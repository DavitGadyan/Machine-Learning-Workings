{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=np.array([3, 5])\n",
    "weights={'node_0': np.array([2, 4]), 'node_1': np.array([ 4, -5]), 'output': np.array([2, 7])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-39\n"
     ]
    }
   ],
   "source": [
    "# Calculate node 0 value: node_0_value\n",
    "node_0_value = (input_data * weights['node_0']).sum()\n",
    "\n",
    "# Calculate node 1 value: node_1_value\n",
    "node_1_value = (input_data * weights['node_1']).sum()\n",
    "\n",
    "\n",
    "# Put node values into array: hidden_layer_outputs\n",
    "hidden_layer_outputs = np.array([node_0_value, node_1_value])\n",
    "\n",
    "# Calculate output: output\n",
    "output = (hidden_layer_outputs*weights['output']).sum()\n",
    "\n",
    "# Print output\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need activation function relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "def relu(input):\n",
    "    '''Define your relu activation function here'''\n",
    "    # Calculate the value for the output of the relu function: output\n",
    "    output = max(input, 0)\n",
    "    \n",
    "    # Return the value just calculated\n",
    "    return(output)\n",
    "\n",
    "# Calculate node 0 value: node_0_output\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = relu(node_0_input)\n",
    "\n",
    "# Calculate node 1 value: node_1_output\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = relu(node_1_input)\n",
    "\n",
    "# Put node values into array: hidden_layer_outputs\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "\n",
    "# Calculate model output (do not apply relu)\n",
    "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "# Print model output\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=[np.array([3, 5]), np.array([ 1, -1]), np.array([0, 0]), np.array([8, 4])]\n",
    "weights={'node_0': np.array([2, 4]), 'node_1': np.array([ 4, -5]), 'output': np.array([2, 7])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 63, 0, 148]\n"
     ]
    }
   ],
   "source": [
    "# Define predict_with_network()\n",
    "def predict_with_network(input_data_row, weights):\n",
    "\n",
    "    # Calculate node 0 value\n",
    "    node_0_input = (input_data_row*weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    # Calculate node 1 value\n",
    "    node_1_input = (input_data_row*weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_layer_outputs\n",
    "    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "    \n",
    "    # Calculate model output\n",
    "    input_to_final_layer = (hidden_layer_outputs*weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "    \n",
    "    # Return model output\n",
    "    return(model_output)\n",
    "\n",
    "\n",
    "# Create empty list to store prediction results\n",
    "results = []\n",
    "for input_data_row in input_data:\n",
    "    # Append prediction to results\n",
    "    results.append(predict_with_network(input_data_row, weights))\n",
    "\n",
    "# Print results\n",
    "print(results)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights={'node_0_0': np.array([2, 4]),\n",
    " 'node_0_1': np.array([ 4, -5]),\n",
    " 'node_1_0': np.array([-1,  2]),\n",
    " 'node_1_1': np.array([1, 2]),\n",
    " 'output': np.array([2, 7])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=np.array([3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "def predict_with_network(input_data):\n",
    "    # Calculate node 0 in the first hidden layer\n",
    "    node_0_0_input = (input_data * weights['node_0_0'] ).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "\n",
    "    # Calculate node 1 in the first hidden layer\n",
    "    node_0_1_input = (input_data * weights['node_0_1'] ).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_0_outputs\n",
    "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
    "    \n",
    "    # Calculate node 0 in the second hidden layer\n",
    "    node_1_0_input = (hidden_0_outputs * weights['node_1_0'] ).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "\n",
    "    # Calculate node 1 in the second hidden layer\n",
    "    node_1_1_input = (hidden_0_outputs * weights['node_1_1'] ).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_1_outputs\n",
    "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
    "\n",
    "    # Calculate model output: model_output\n",
    "    model_output = relu((hidden_1_outputs*weights['output']).sum())\n",
    "    \n",
    "    # Return model_output\n",
    "    return(model_output)\n",
    "\n",
    "output = predict_with_network(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weights that determine the features/interactions in Neural Networks are created by the model training process which sets them to optimize predictive accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The last layers capture the most complex interactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_with_network(input_data,weights):\n",
    "    # Calculate node 0 in the first hidden layer\n",
    "    node_0_0_input = (input_data * weights['node_0'] ).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "\n",
    "    # Calculate node 1 in the first hidden layer\n",
    "    node_0_1_input = (input_data * weights['node_1'] ).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_0_outputs\n",
    "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
    "\n",
    "    # Calculate model output: model_output\n",
    "    model_output = relu((hidden_0_outputs*weights['output']).sum())\n",
    "    \n",
    "    # Return model_output\n",
    "    return(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# The data point you will make a prediction for\n",
    "input_data = np.array([0, 3])\n",
    "\n",
    "# Sample weights\n",
    "weights_0 = {'node_0': [2, 1],\n",
    "             'node_1': [1, 2],\n",
    "             'output': [1, 1]\n",
    "            }\n",
    "\n",
    "# The actual target value, used to calculate the error\n",
    "target_actual = 3\n",
    "\n",
    "# Make prediction using original weights\n",
    "model_output_0 = predict_with_network(input_data, weights_0)\n",
    "\n",
    "# Calculate error: error_0\n",
    "error_0 = model_output_0 - target_actual\n",
    "\n",
    "# Create weights that cause the network to make perfect prediction (3): weights_1\n",
    "weights_1 = {'node_0': [2, 1],\n",
    "             'node_1': [1, 2],\n",
    "             'output': [1, 0]\n",
    "            }\n",
    "\n",
    "# Make prediction using new weights: model_output_1\n",
    "model_output_1 = predict_with_network(input_data, weights_1)\n",
    "\n",
    "# Calculate error: error_1\n",
    "error_1 = model_output_1 - target_actual\n",
    "\n",
    "# Print error_0 and error_1\n",
    "print(error_0)\n",
    "print(error_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data=[np.array([0, 3]), np.array([1, 2]), np.array([-1, -2]), np.array([4, 0])]\n",
    "target_actuals=[1, 3, 5, 7]\n",
    "weights_0={'node_0': np.array([2, 1]), 'node_1': np.array([1, 2]), 'output': np.array([1, 1])}\n",
    "weights_1={'node_0': np.array([2, 1]),\n",
    " 'node_1': np.array([1. , 1.5]),\n",
    " 'output': np.array([1. , 1.5])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with weights_0: 37.500000\n",
      "Mean squared error with weights_1: 49.890625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create model_output_0 \n",
    "model_output_0 = []\n",
    "# Create model_output_1\n",
    "model_output_1 = []\n",
    "\n",
    "# Loop over input_data\n",
    "for row in input_data:\n",
    "    # Append prediction to model_output_0\n",
    "    model_output_0.append(predict_with_network(row,weights_0))\n",
    "    \n",
    "    # Append prediction to model_output_1\n",
    "    model_output_1.append(predict_with_network(row,weights_1))\n",
    "\n",
    "# Calculate the mean squared error for model_output_0: mse_0\n",
    "mse_0 = mean_squared_error(target_actuals,model_output_0)\n",
    "\n",
    "# Calculate the mean squared error for model_output_1: mse_1\n",
    "mse_1 = mean_squared_error(target_actuals,model_output_1)\n",
    "\n",
    "# Print mse_0 and mse_1\n",
    "print(\"Mean squared error with weights_0: %f\" %mse_0)\n",
    "print(\"Mean squared error with weights_1: %f\" %mse_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights=np.array([0, 2, 1])\n",
    "input_data=np.array([1, 2, 3])\n",
    "target=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14 -28 -42]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the predictions: preds\n",
    "preds = (input_data*weights).sum()\n",
    "\n",
    "# Calculate the error: error\n",
    "error = target-preds\n",
    "\n",
    "# Calculate the slope: slope\n",
    "slope = 2 * error * input_data\n",
    "\n",
    "# Print the slope\n",
    "print(slope)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "5.04\n"
     ]
    }
   ],
   "source": [
    "# Set the learning rate: learning_rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Calculate the predictions: preds\n",
    "preds = (weights * input_data).sum()\n",
    "\n",
    "# Calculate the error: error\n",
    "error = preds - target\n",
    "\n",
    "# Calculate the slope: slope\n",
    "slope = 2 * input_data * error\n",
    "\n",
    "# Update the weights: weights_updated\n",
    "weights_updated = weights-learning_rate*slope\n",
    "\n",
    "# Get updated predictions: preds_updated\n",
    "preds_updated = (input_data*weights_updated).sum()\n",
    "\n",
    "# Calculate updated error: error_updated\n",
    "error_updated = preds_updated - target\n",
    "\n",
    "# Print the original error\n",
    "print(error)\n",
    "\n",
    "# Print the updated error\n",
    "print(error_updated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('hourly_wages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.024064</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>13.018727</td>\n",
       "      <td>17.822097</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>0.458801</td>\n",
       "      <td>0.655431</td>\n",
       "      <td>0.292135</td>\n",
       "      <td>0.185393</td>\n",
       "      <td>0.044944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.139097</td>\n",
       "      <td>0.384360</td>\n",
       "      <td>2.615373</td>\n",
       "      <td>12.379710</td>\n",
       "      <td>11.726573</td>\n",
       "      <td>0.498767</td>\n",
       "      <td>0.475673</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>0.388981</td>\n",
       "      <td>0.207375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.780000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wage_per_hour       union  education_yrs  experience_yrs         age  \\\n",
       "count     534.000000  534.000000     534.000000      534.000000  534.000000   \n",
       "mean        9.024064    0.179775      13.018727       17.822097   36.833333   \n",
       "std         5.139097    0.384360       2.615373       12.379710   11.726573   \n",
       "min         1.000000    0.000000       2.000000        0.000000   18.000000   \n",
       "25%         5.250000    0.000000      12.000000        8.000000   28.000000   \n",
       "50%         7.780000    0.000000      12.000000       15.000000   35.000000   \n",
       "75%        11.250000    0.000000      15.000000       26.000000   44.000000   \n",
       "max        44.500000    1.000000      18.000000       55.000000   64.000000   \n",
       "\n",
       "           female        marr       south  manufacturing  construction  \n",
       "count  534.000000  534.000000  534.000000     534.000000    534.000000  \n",
       "mean     0.458801    0.655431    0.292135       0.185393      0.044944  \n",
       "std      0.498767    0.475673    0.455170       0.388981      0.207375  \n",
       "min      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "25%      0.000000    0.000000    0.000000       0.000000      0.000000  \n",
       "50%      0.000000    1.000000    0.000000       0.000000      0.000000  \n",
       "75%      1.000000    1.000000    1.000000       0.000000      0.000000  \n",
       "max      1.000000    1.000000    1.000000       1.000000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target=df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaya\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import numpy\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32,activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To compile the model, you need to specify the optimizer and loss function to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# there are many options for backpropogation but we choose adam.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "534/534 [==============================] - 0s 469us/step - loss: 232.7405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x5477930588>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target,,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('titanic_all_numeric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  male  \\\n",
       "0           0       3  22.000000      1      0    7.2500     1   \n",
       "1           1       1  38.000000      1      0   71.2833     0   \n",
       "2           1       3  26.000000      0      0    7.9250     0   \n",
       "3           1       1  35.000000      1      0   53.1000     0   \n",
       "4           0       3  35.000000      0      0    8.0500     1   \n",
       "5           0       3  29.699118      0      0    8.4583     1   \n",
       "6           0       1  54.000000      0      0   51.8625     1   \n",
       "7           0       3   2.000000      3      1   21.0750     1   \n",
       "8           1       3  27.000000      0      2   11.1333     0   \n",
       "9           1       2  14.000000      1      0   30.0708     0   \n",
       "10          1       3   4.000000      1      1   16.7000     0   \n",
       "11          1       1  58.000000      0      0   26.5500     0   \n",
       "12          0       3  20.000000      0      0    8.0500     1   \n",
       "13          0       3  39.000000      1      5   31.2750     1   \n",
       "14          0       3  14.000000      0      0    7.8542     0   \n",
       "15          1       2  55.000000      0      0   16.0000     0   \n",
       "16          0       3   2.000000      4      1   29.1250     1   \n",
       "17          1       2  29.699118      0      0   13.0000     1   \n",
       "18          0       3  31.000000      1      0   18.0000     0   \n",
       "19          1       3  29.699118      0      0    7.2250     0   \n",
       "20          0       2  35.000000      0      0   26.0000     1   \n",
       "21          1       2  34.000000      0      0   13.0000     1   \n",
       "22          1       3  15.000000      0      0    8.0292     0   \n",
       "23          1       1  28.000000      0      0   35.5000     1   \n",
       "24          0       3   8.000000      3      1   21.0750     0   \n",
       "25          1       3  38.000000      1      5   31.3875     0   \n",
       "26          0       3  29.699118      0      0    7.2250     1   \n",
       "27          0       1  19.000000      3      2  263.0000     1   \n",
       "28          1       3  29.699118      0      0    7.8792     0   \n",
       "29          0       3  29.699118      0      0    7.8958     1   \n",
       "..        ...     ...        ...    ...    ...       ...   ...   \n",
       "861         0       2  21.000000      1      0   11.5000     1   \n",
       "862         1       1  48.000000      0      0   25.9292     0   \n",
       "863         0       3  29.699118      8      2   69.5500     0   \n",
       "864         0       2  24.000000      0      0   13.0000     1   \n",
       "865         1       2  42.000000      0      0   13.0000     0   \n",
       "866         1       2  27.000000      1      0   13.8583     0   \n",
       "867         0       1  31.000000      0      0   50.4958     1   \n",
       "868         0       3  29.699118      0      0    9.5000     1   \n",
       "869         1       3   4.000000      1      1   11.1333     1   \n",
       "870         0       3  26.000000      0      0    7.8958     1   \n",
       "871         1       1  47.000000      1      1   52.5542     0   \n",
       "872         0       1  33.000000      0      0    5.0000     1   \n",
       "873         0       3  47.000000      0      0    9.0000     1   \n",
       "874         1       2  28.000000      1      0   24.0000     0   \n",
       "875         1       3  15.000000      0      0    7.2250     0   \n",
       "876         0       3  20.000000      0      0    9.8458     1   \n",
       "877         0       3  19.000000      0      0    7.8958     1   \n",
       "878         0       3  29.699118      0      0    7.8958     1   \n",
       "879         1       1  56.000000      0      1   83.1583     0   \n",
       "880         1       2  25.000000      0      1   26.0000     0   \n",
       "881         0       3  33.000000      0      0    7.8958     1   \n",
       "882         0       3  22.000000      0      0   10.5167     0   \n",
       "883         0       2  28.000000      0      0   10.5000     1   \n",
       "884         0       3  25.000000      0      0    7.0500     1   \n",
       "885         0       3  39.000000      0      5   29.1250     0   \n",
       "886         0       2  27.000000      0      0   13.0000     1   \n",
       "887         1       1  19.000000      0      0   30.0000     0   \n",
       "888         0       3  29.699118      1      2   23.4500     0   \n",
       "889         1       1  26.000000      0      0   30.0000     1   \n",
       "890         0       3  32.000000      0      0    7.7500     1   \n",
       "\n",
       "     age_was_missing  embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0              False                        0                         0   \n",
       "1              False                        1                         0   \n",
       "2              False                        0                         0   \n",
       "3              False                        0                         0   \n",
       "4              False                        0                         0   \n",
       "5               True                        0                         1   \n",
       "6              False                        0                         0   \n",
       "7              False                        0                         0   \n",
       "8              False                        0                         0   \n",
       "9              False                        1                         0   \n",
       "10             False                        0                         0   \n",
       "11             False                        0                         0   \n",
       "12             False                        0                         0   \n",
       "13             False                        0                         0   \n",
       "14             False                        0                         0   \n",
       "15             False                        0                         0   \n",
       "16             False                        0                         1   \n",
       "17              True                        0                         0   \n",
       "18             False                        0                         0   \n",
       "19              True                        1                         0   \n",
       "20             False                        0                         0   \n",
       "21             False                        0                         0   \n",
       "22             False                        0                         1   \n",
       "23             False                        0                         0   \n",
       "24             False                        0                         0   \n",
       "25             False                        0                         0   \n",
       "26              True                        1                         0   \n",
       "27             False                        0                         0   \n",
       "28              True                        0                         1   \n",
       "29              True                        0                         0   \n",
       "..               ...                      ...                       ...   \n",
       "861            False                        0                         0   \n",
       "862            False                        0                         0   \n",
       "863             True                        0                         0   \n",
       "864            False                        0                         0   \n",
       "865            False                        0                         0   \n",
       "866            False                        1                         0   \n",
       "867            False                        0                         0   \n",
       "868             True                        0                         0   \n",
       "869            False                        0                         0   \n",
       "870            False                        0                         0   \n",
       "871            False                        0                         0   \n",
       "872            False                        0                         0   \n",
       "873            False                        0                         0   \n",
       "874            False                        1                         0   \n",
       "875            False                        1                         0   \n",
       "876            False                        0                         0   \n",
       "877            False                        0                         0   \n",
       "878             True                        0                         0   \n",
       "879            False                        1                         0   \n",
       "880            False                        0                         0   \n",
       "881            False                        0                         0   \n",
       "882            False                        0                         0   \n",
       "883            False                        0                         0   \n",
       "884            False                        0                         0   \n",
       "885            False                        0                         1   \n",
       "886            False                        0                         0   \n",
       "887            False                        0                         0   \n",
       "888             True                        0                         0   \n",
       "889            False                        1                         0   \n",
       "890            False                        0                         1   \n",
       "\n",
       "     embarked_from_southampton  \n",
       "0                            1  \n",
       "1                            0  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            1  \n",
       "5                            0  \n",
       "6                            1  \n",
       "7                            1  \n",
       "8                            1  \n",
       "9                            0  \n",
       "10                           1  \n",
       "11                           1  \n",
       "12                           1  \n",
       "13                           1  \n",
       "14                           1  \n",
       "15                           1  \n",
       "16                           0  \n",
       "17                           1  \n",
       "18                           1  \n",
       "19                           0  \n",
       "20                           1  \n",
       "21                           1  \n",
       "22                           0  \n",
       "23                           1  \n",
       "24                           1  \n",
       "25                           1  \n",
       "26                           0  \n",
       "27                           1  \n",
       "28                           0  \n",
       "29                           1  \n",
       "..                         ...  \n",
       "861                          1  \n",
       "862                          1  \n",
       "863                          1  \n",
       "864                          1  \n",
       "865                          1  \n",
       "866                          0  \n",
       "867                          1  \n",
       "868                          1  \n",
       "869                          1  \n",
       "870                          1  \n",
       "871                          1  \n",
       "872                          1  \n",
       "873                          1  \n",
       "874                          0  \n",
       "875                          0  \n",
       "876                          1  \n",
       "877                          1  \n",
       "878                          1  \n",
       "879                          0  \n",
       "880                          1  \n",
       "881                          1  \n",
       "882                          1  \n",
       "883                          1  \n",
       "884                          1  \n",
       "885                          0  \n",
       "886                          1  \n",
       "887                          1  \n",
       "888                          1  \n",
       "889                          0  \n",
       "890                          0  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors =df.drop(['survived'], axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 200us/step - loss: 1.9405 - acc: 0.5758\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 36us/step - loss: 0.9714 - acc: 0.6162\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 40us/step - loss: 0.7508 - acc: 0.6442\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 37us/step - loss: 0.6458 - acc: 0.6723\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 35us/step - loss: 0.6683 - acc: 0.6655\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 40us/step - loss: 0.6351 - acc: 0.6891\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 37us/step - loss: 0.6070 - acc: 0.6925\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 36us/step - loss: 0.6141 - acc: 0.6869\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 36us/step - loss: 0.6125 - acc: 0.6779\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 36us/step - loss: 0.6236 - acc: 0.6857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x54790a0f98>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "predictors =df.drop(['survived'], axis=1).as_matrix()\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "n_cols=predictors.shape[1]\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32,activation='relu',input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target,epochs=10) # need to specify # of epochs in fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred_data=np.array([[2, 34.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 26.25, 0, False, 0, 0, 1],\n",
    "       [1, 11.0, 1, 2, 120.0, 1, False, 0, 0, 1],\n",
    "       [3, 0.42, 0, 1, 8.5167, 1, False, 1, 0, 0],\n",
    "       [3, 27.0, 0, 0, 6.975, 1, False, 0, 0, 1],\n",
    "       [3, 31.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 7.775, 0, False, 0, 0, 1],\n",
    "       [2, 39.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 33.0, 1, 0, 53.1, 0, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8875, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 0, 24.15, 1, False, 0, 0, 1],\n",
    "       [2, 35.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 6.0, 4, 2, 31.275, 0, False, 0, 0, 1],\n",
    "       [3, 30.5, 0, 0, 8.05, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 0.0, 1, True, 0, 0, 1],\n",
    "       [3, 23.0, 0, 0, 7.925, 0, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 43.0, 0, 0, 6.45, 1, False, 0, 0, 1],\n",
    "       [3, 10.0, 3, 2, 27.9, 1, False, 0, 0, 1],\n",
    "       [1, 52.0, 1, 1, 93.5, 0, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [1, 38.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 1, 12.475, 0, False, 0, 0, 1],\n",
    "       [3, 2.0, 4, 1, 39.6875, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 6.95, 1, True, 0, 1, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 56.4958, 1, True, 0, 0, 1],\n",
    "       [2, 1.0, 0, 2, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.75, 1, True, 0, 1, 0],\n",
    "       [1, 62.0, 0, 0, 80.0, 0, False, 0, 0, 0],\n",
    "       [3, 15.0, 1, 0, 14.4542, 0, False, 1, 0, 0],\n",
    "       [2, 0.83, 1, 1, 18.75, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 23.0, 0, 0, 7.8542, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 8.3, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 1, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [3, 21.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 8.05, 1, True, 0, 0, 1],\n",
    "       [3, 32.0, 0, 0, 56.4958, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 29.7, 1, True, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 7.925, 1, False, 0, 0, 1],\n",
    "       [2, 16.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [1, 30.0, 0, 0, 31.0, 0, False, 1, 0, 0],\n",
    "       [3, 34.5, 0, 0, 6.4375, 1, False, 1, 0, 0],\n",
    "       [3, 17.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 42.0, 0, 0, 7.55, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 1, True, 0, 0, 1],\n",
    "       [3, 35.0, 0, 0, 7.8958, 1, False, 1, 0, 0],\n",
    "       [2, 28.0, 0, 1, 33.0, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 1, 0, 89.1042, 0, True, 1, 0, 0],\n",
    "       [3, 4.0, 4, 2, 31.275, 1, False, 0, 0, 1],\n",
    "       [3, 74.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [3, 9.0, 1, 1, 15.2458, 0, False, 1, 0, 0],\n",
    "       [1, 16.0, 0, 1, 39.4, 0, False, 0, 0, 1],\n",
    "       [2, 44.0, 1, 0, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 1, 9.35, 0, False, 0, 0, 1],\n",
    "       [1, 45.0, 1, 1, 164.8667, 0, False, 0, 0, 1],\n",
    "       [1, 51.0, 0, 0, 26.55, 1, False, 0, 0, 1],\n",
    "       [3, 24.0, 0, 3, 19.2583, 0, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 41.0, 2, 0, 14.1083, 1, False, 0, 0, 1],\n",
    "       [2, 21.0, 1, 0, 11.5, 1, False, 0, 0, 1],\n",
    "       [1, 48.0, 0, 0, 25.9292, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 0, True, 0, 0, 1],\n",
    "       [2, 24.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 42.0, 0, 0, 13.0, 0, False, 0, 0, 1],\n",
    "       [2, 27.0, 1, 0, 13.8583, 0, False, 1, 0, 0],\n",
    "       [1, 31.0, 0, 0, 50.4958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 9.5, 1, True, 0, 0, 1],\n",
    "       [3, 4.0, 1, 1, 11.1333, 1, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [1, 47.0, 1, 1, 52.5542, 0, False, 0, 0, 1],\n",
    "       [1, 33.0, 0, 0, 5.0, 1, False, 0, 0, 1],\n",
    "       [3, 47.0, 0, 0, 9.0, 1, False, 0, 0, 1],\n",
    "       [2, 28.0, 1, 0, 24.0, 0, False, 1, 0, 0],\n",
    "       [3, 15.0, 0, 0, 7.225, 0, False, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 9.8458, 1, False, 0, 0, 1],\n",
    "       [3, 19.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.8958, 1, True, 0, 0, 1],\n",
    "       [1, 56.0, 0, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [2, 25.0, 0, 1, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 33.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 22.0, 0, 0, 10.5167, 0, False, 0, 0, 1],\n",
    "       [2, 28.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 25.0, 0, 0, 7.05, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 5, 29.125, 0, False, 0, 1, 0],\n",
    "       [2, 27.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 19.0, 0, 0, 30.0, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 1, 2, 23.45, 0, True, 0, 0, 1],\n",
    "       [1, 26.0, 0, 0, 30.0, 1, False, 1, 0, 0],\n",
    "       [3, 32.0, 0, 0, 7.75, 1, False, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4686964  0.5183212  0.8382126  0.5425625  0.35186598 0.34510636\n",
      " 0.17149828 0.45409977 0.4597752  0.64885294 0.40603918 0.4972925\n",
      " 0.4549398  0.5078585  0.3598598  0.21221669 0.42001513 0.5538161\n",
      " 0.22552137 0.49748832 0.75675076 0.43264878 0.17688936 0.44919536\n",
      " 0.54381657 0.31949037 0.6167444  0.63064456 0.34659457 0.7058384\n",
      " 0.48292565 0.5433569  0.35587728 0.44165632 0.45868605 0.7467027\n",
      " 0.45507917 0.35170746 0.62663287 0.5522942  0.45333418 0.48889506\n",
      " 0.5634607  0.3017368  0.46220383 0.25912976 0.5486729  0.34496173\n",
      " 0.54351246 0.78651196 0.5194691  0.10679558 0.4732449  0.60690784\n",
      " 0.5052632  0.45408016 0.91296536 0.5195543  0.44867277 0.35587728\n",
      " 0.4337217  0.47875854 0.51985127 0.56110513 0.48659346 0.45236054\n",
      " 0.47560495 0.63565934 0.42077896 0.5099934  0.4064532  0.604964\n",
      " 0.35971946 0.26369587 0.52263844 0.4551499  0.46252263 0.45497304\n",
      " 0.34696677 0.71437323 0.5292582  0.3333059  0.46009058 0.4674177\n",
      " 0.37693033 0.44857883 0.48121867 0.5752273  0.47022957 0.557891\n",
      " 0.33916327]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving, reloading and using your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4686964 , 0.5183212 , 0.8382126 , 0.5425625 , 0.35186598,\n",
       "       0.34510636, 0.17149828, 0.45409977, 0.4597752 , 0.64885294,\n",
       "       0.40603918, 0.4972925 , 0.4549398 , 0.5078585 , 0.3598598 ,\n",
       "       0.21221669, 0.42001513, 0.5538161 , 0.22552137, 0.49748832,\n",
       "       0.75675076, 0.43264878, 0.17688936, 0.44919536, 0.54381657,\n",
       "       0.31949037, 0.6167444 , 0.63064456, 0.34659457, 0.7058384 ,\n",
       "       0.48292565, 0.5433569 , 0.35587728, 0.44165632, 0.45868605,\n",
       "       0.7467027 , 0.45507917, 0.35170746, 0.62663287, 0.5522942 ,\n",
       "       0.45333418, 0.48889506, 0.5634607 , 0.3017368 , 0.46220383,\n",
       "       0.25912976, 0.5486729 , 0.34496173, 0.54351246, 0.78651196,\n",
       "       0.5194691 , 0.10679558, 0.4732449 , 0.60690784, 0.5052632 ,\n",
       "       0.45408016, 0.91296536, 0.5195543 , 0.44867277, 0.35587728,\n",
       "       0.4337217 , 0.47875854, 0.51985127, 0.56110513, 0.48659346,\n",
       "       0.45236054, 0.47560495, 0.63565934, 0.42077896, 0.5099934 ,\n",
       "       0.4064532 , 0.604964  , 0.35971946, 0.26369587, 0.52263844,\n",
       "       0.4551499 , 0.46252263, 0.45497304, 0.34696677, 0.71437323,\n",
       "       0.5292582 , 0.3333059 , 0.46009058, 0.4674177 , 0.37693033,\n",
       "       0.44857883, 0.48121867, 0.5752273 , 0.47022957, 0.557891  ,\n",
       "       0.33916327], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model.save('model_file.h5')\n",
    "my_model = load_model('model_file.h5')\n",
    "predictions = my_model.predict(pred_data)\n",
    "probability_true = predictions[:,1]\n",
    "probability_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 457us/step - loss: 1.1269 - acc: 0.6902\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 40us/step - loss: 1.1250 - acc: 0.6902\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 44us/step - loss: 1.1231 - acc: 0.6902\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 49us/step - loss: 1.1213 - acc: 0.6902\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 42us/step - loss: 1.1194 - acc: 0.6902\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 45us/step - loss: 1.1176 - acc: 0.6902\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 45us/step - loss: 1.1157 - acc: 0.6902\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 42us/step - loss: 1.1139 - acc: 0.6902\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 44us/step - loss: 1.1121 - acc: 0.6902\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 43us/step - loss: 1.1102 - acc: 0.6902\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 443us/step - loss: 2.4223 - acc: 0.5645\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 43us/step - loss: 0.7993 - acc: 0.6409\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 43us/step - loss: 0.7274 - acc: 0.6599\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 51us/step - loss: 0.6212 - acc: 0.6813\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 42us/step - loss: 0.6176 - acc: 0.6801\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.5888 - acc: 0.6936\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 48us/step - loss: 0.6170 - acc: 0.6768\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 57us/step - loss: 0.5971 - acc: 0.6914\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 47us/step - loss: 0.6113 - acc: 0.6835\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 49us/step - loss: 0.5893 - acc: 0.6902\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s 463us/step - loss: 9.6868 - acc: 0.3906\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 46us/step - loss: 9.9314 - acc: 0.3838\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 44us/step - loss: 9.9314 - acc: 0.3838\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 51us/step - loss: 9.9314 - acc: 0.3838\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 45us/step - loss: 9.9314 - acc: 0.3838\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 45us/step - loss: 9.9314 - acc: 0.3838\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 46us/step - loss: 9.9314 - acc: 0.3838\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 46us/step - loss: 9.9314 - acc: 0.3838\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 45us/step - loss: 9.9314 - acc: 0.3838\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 46us/step - loss: 9.9314 - acc: 0.3838\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model(input_shape=(n_cols,))\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors,target,epochs=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 1s 980us/step - loss: 0.8286 - acc: 0.6067 - val_loss: 0.7059 - val_acc: 0.6866\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.7019 - acc: 0.6629 - val_loss: 0.6306 - val_acc: 0.6978\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.6859 - acc: 0.6372 - val_loss: 0.5176 - val_acc: 0.7500\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.5870 - acc: 0.6950 - val_loss: 0.5877 - val_acc: 0.7239\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.5999 - acc: 0.6886 - val_loss: 0.5113 - val_acc: 0.7276\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.6034 - acc: 0.6886 - val_loss: 0.4919 - val_acc: 0.7687\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.6927 - acc: 0.6902 - val_loss: 0.4839 - val_acc: 0.7687\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.6762 - acc: 0.7095 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.5909 - acc: 0.7319 - val_loss: 0.5120 - val_acc: 0.7910\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.6637 - acc: 0.7191 - val_loss: 1.0122 - val_acc: 0.6493\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors,target,validation_split=0.3,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 0.7538 - acc: 0.6292 - val_loss: 0.5808 - val_acc: 0.7388\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.7770 - acc: 0.6067 - val_loss: 0.6180 - val_acc: 0.7127\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.6833 - acc: 0.6709 - val_loss: 0.6338 - val_acc: 0.7090\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.7049 - acc: 0.6485 - val_loss: 0.5357 - val_acc: 0.7351\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.5944 - acc: 0.7095 - val_loss: 0.5572 - val_acc: 0.7649\n",
      "Epoch 6/30\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.5883 - acc: 0.7095 - val_loss: 0.5015 - val_acc: 0.7575\n",
      "Epoch 7/30\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.5738 - acc: 0.7432 - val_loss: 0.6689 - val_acc: 0.6418\n",
      "Epoch 8/30\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.6258 - acc: 0.6902 - val_loss: 0.5157 - val_acc: 0.7948\n",
      "Epoch 9/30\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.5996 - acc: 0.6918 - val_loss: 0.4803 - val_acc: 0.7575\n",
      "Epoch 10/30\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.5518 - acc: 0.7335 - val_loss: 0.4976 - val_acc: 0.8022\n",
      "Epoch 11/30\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.5593 - acc: 0.7384 - val_loss: 0.4565 - val_acc: 0.7761\n",
      "Epoch 12/30\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.5335 - acc: 0.7400 - val_loss: 0.4657 - val_acc: 0.7873\n",
      "Epoch 13/30\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.5773 - acc: 0.7271 - val_loss: 0.4509 - val_acc: 0.8134\n",
      "Epoch 14/30\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.5299 - acc: 0.7544 - val_loss: 0.4367 - val_acc: 0.8022\n",
      "Epoch 15/30\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.5246 - acc: 0.7592 - val_loss: 0.4557 - val_acc: 0.8172\n",
      "Epoch 16/30\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.5118 - acc: 0.7624 - val_loss: 0.4844 - val_acc: 0.7463\n",
      "Epoch 17/30\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.5201 - acc: 0.7673 - val_loss: 0.6677 - val_acc: 0.6828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x5404c03f60>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target,epochs=30,validation_split=0.3,callbacks=[early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(10, activation='relu', input_shape = input_shape))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAJQCAYAAADMqko4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x540bf1a198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so in the above graph which outputs new results each time we run.. you can observe that blue line which is model with hidden layers equal to 100 shows better than red model with hidden layers equal to 10... basically the lower val_loss the better model in prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_1 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_1.add(Dense(50, activation='relu',input_shape=input_shape))\n",
    "model_1.add(Dense(2,activation='softmax'))\n",
    "model_1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5414a56fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation='relu',input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu',input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu',input_shape=input_shape))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2,activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As before each time we run code it outputs different results... nevertheless when we have data on hand depending on it we need to construct neural networks with different architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('mnist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...    0.608  0.609  \\\n",
       "0     4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1     3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "2     0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "3     2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "4     8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "5     8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "6     1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "7     2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "8     6  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "9     9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "10    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "11    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "12    7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "13    9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "14    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "15    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "16    2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "17    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "18    6  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "19    5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "20    0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "21    4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "22    5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "23    3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "24    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "25    2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "26    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "27    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "28    0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "29    5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "...  .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...    ...   \n",
       "1970  4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1971  4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1972  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1973  3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1974  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1975  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1976  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1977  5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1978  4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1979  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1980  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1981  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1982  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1983  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1984  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1985  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1986  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1987  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1988  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1989  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1990  4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1991  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1992  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1993  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1994  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1995  2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1996  2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1997  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1998  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1999  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "\n",
       "      0.610  0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0         0      0      0      0      0      0      0      0  \n",
       "1         0      0      0      0      0      0      0      0  \n",
       "2         0      0      0      0      0      0      0      0  \n",
       "3         0      0      0      0      0      0      0      0  \n",
       "4         0      0      0      0      0      0      0      0  \n",
       "5         0      0      0      0      0      0      0      0  \n",
       "6         0      0      0      0      0      0      0      0  \n",
       "7         0      0      0      0      0      0      0      0  \n",
       "8         0      0      0      0      0      0      0      0  \n",
       "9         0      0      0      0      0      0      0      0  \n",
       "10        0      0      0      0      0      0      0      0  \n",
       "11        0      0      0      0      0      0      0      0  \n",
       "12        0      0      0      0      0      0      0      0  \n",
       "13        0      0      0      0      0      0      0      0  \n",
       "14        0      0      0      0      0      0      0      0  \n",
       "15        0      0      0      0      0      0      0      0  \n",
       "16        0      0      0      0      0      0      0      0  \n",
       "17        0      0      0      0      0      0      0      0  \n",
       "18        0      0      0      0      0      0      0      0  \n",
       "19        0      0      0      0      0      0      0      0  \n",
       "20        0      0      0      0      0      0      0      0  \n",
       "21        0      0      0      0      0      0      0      0  \n",
       "22        0      0      0      0      0      0      0      0  \n",
       "23        0      0      0      0      0      0      0      0  \n",
       "24        0      0      0      0      0      0      0      0  \n",
       "25        0      0      0      0      0      0      0      0  \n",
       "26        0      0      0      0      0      0      0      0  \n",
       "27        0      0      0      0      0      0      0      0  \n",
       "28        0      0      0      0      0      0      0      0  \n",
       "29        0      0      0      0      0      0      0      0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "1970      0      0      0      0      0      0      0      0  \n",
       "1971      0      0      0      0      0      0      0      0  \n",
       "1972      0      0      0      0      0      0      0      0  \n",
       "1973      0      0      0      0      0      0      0      0  \n",
       "1974      0      0      0      0      0      0      0      0  \n",
       "1975      0      0      0      0      0      0      0      0  \n",
       "1976      0      0      0      0      0      0      0      0  \n",
       "1977      0      0      0      0      0      0      0      0  \n",
       "1978      0      0      0      0      0      0      0      0  \n",
       "1979      0      0      0      0      0      0      0      0  \n",
       "1980      0      0      0      0      0      0      0      0  \n",
       "1981      0      0      0      0      0      0      0      0  \n",
       "1982      0      0      0      0      0      0      0      0  \n",
       "1983      0      0      0      0      0      0      0      0  \n",
       "1984      0      0      0      0      0      0      0      0  \n",
       "1985      0      0      0      0      0      0      0      0  \n",
       "1986      0      0      0      0      0      0      0      0  \n",
       "1987      0      0      0      0      0      0      0      0  \n",
       "1988      0      0      0      0      0      0      0      0  \n",
       "1989      0      0      0      0      0      0      0      0  \n",
       "1990      0      0      0      0      0      0      0      0  \n",
       "1991      0      0      0      0      0      0      0      0  \n",
       "1992      0      0      0      0      0      0      0      0  \n",
       "1993      0      0      0      0      0      0      0      0  \n",
       "1994      0      0      0      0      0      0      0      0  \n",
       "1995      0      0      0      0      0      0      0      0  \n",
       "1996      0      0      0      0      0      0      0      0  \n",
       "1997      0      0      0      0      0      0      0      0  \n",
       "1998      0      0      0      0      0      0      0      0  \n",
       "1999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[2000 rows x 785 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/40\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 11.3005 - acc: 0.2850 - val_loss: 11.0327 - val_acc: 0.3050\n",
      "Epoch 2/40\n",
      "1400/1400 [==============================] - 0s 158us/step - loss: 9.9991 - acc: 0.3729 - val_loss: 10.6262 - val_acc: 0.3367\n",
      "Epoch 3/40\n",
      "1400/1400 [==============================] - 0s 156us/step - loss: 9.5144 - acc: 0.4014 - val_loss: 9.3311 - val_acc: 0.4133\n",
      "Epoch 4/40\n",
      "1400/1400 [==============================] - 0s 154us/step - loss: 8.4532 - acc: 0.4700 - val_loss: 8.6489 - val_acc: 0.4533\n",
      "Epoch 5/40\n",
      "1400/1400 [==============================] - 0s 156us/step - loss: 8.2133 - acc: 0.4821 - val_loss: 8.6145 - val_acc: 0.4567\n",
      "Epoch 6/40\n",
      "1400/1400 [==============================] - 0s 154us/step - loss: 7.9169 - acc: 0.5036 - val_loss: 8.4319 - val_acc: 0.4733\n",
      "Epoch 7/40\n",
      "1400/1400 [==============================] - 0s 157us/step - loss: 7.4838 - acc: 0.5286 - val_loss: 8.1710 - val_acc: 0.4867\n",
      "Epoch 8/40\n",
      "1400/1400 [==============================] - 0s 156us/step - loss: 7.6270 - acc: 0.5186 - val_loss: 7.7786 - val_acc: 0.5117\n",
      "Epoch 9/40\n",
      "1400/1400 [==============================] - 0s 155us/step - loss: 6.8890 - acc: 0.5679 - val_loss: 7.4298 - val_acc: 0.5300\n",
      "Epoch 10/40\n",
      "1400/1400 [==============================] - 0s 161us/step - loss: 6.4069 - acc: 0.5993 - val_loss: 7.3478 - val_acc: 0.5383\n",
      "Epoch 11/40\n",
      "1400/1400 [==============================] - 0s 157us/step - loss: 6.2444 - acc: 0.6071 - val_loss: 7.7099 - val_acc: 0.5117\n",
      "Epoch 12/40\n",
      "1400/1400 [==============================] - 0s 154us/step - loss: 6.2226 - acc: 0.6064 - val_loss: 7.0424 - val_acc: 0.5583\n",
      "Epoch 13/40\n",
      "1400/1400 [==============================] - 0s 166us/step - loss: 5.8510 - acc: 0.6314 - val_loss: 6.7510 - val_acc: 0.5733\n",
      "Epoch 14/40\n",
      "1400/1400 [==============================] - 0s 202us/step - loss: 5.8607 - acc: 0.6314 - val_loss: 6.3798 - val_acc: 0.6000\n",
      "Epoch 15/40\n",
      "1400/1400 [==============================] - 0s 231us/step - loss: 5.6171 - acc: 0.6450 - val_loss: 6.2066 - val_acc: 0.6067\n",
      "Epoch 16/40\n",
      "1400/1400 [==============================] - 0s 234us/step - loss: 5.6920 - acc: 0.6436 - val_loss: 6.6665 - val_acc: 0.5750\n",
      "Epoch 17/40\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 5.8445 - acc: 0.6357 - val_loss: 6.6534 - val_acc: 0.5783\n",
      "Epoch 18/40\n",
      "1400/1400 [==============================] - 0s 163us/step - loss: 5.7545 - acc: 0.6386 - val_loss: 6.4675 - val_acc: 0.5933\n",
      "Epoch 19/40\n",
      "1400/1400 [==============================] - 0s 163us/step - loss: 5.5681 - acc: 0.6514 - val_loss: 6.5288 - val_acc: 0.5900\n",
      "Epoch 20/40\n",
      "1400/1400 [==============================] - 0s 164us/step - loss: 5.5736 - acc: 0.6500 - val_loss: 6.8194 - val_acc: 0.5733\n",
      "Epoch 21/40\n",
      "1400/1400 [==============================] - 0s 163us/step - loss: 5.4356 - acc: 0.6579 - val_loss: 6.2971 - val_acc: 0.6000\n",
      "Epoch 22/40\n",
      "1400/1400 [==============================] - 0s 168us/step - loss: 5.5159 - acc: 0.6543 - val_loss: 6.3581 - val_acc: 0.6000\n",
      "Epoch 23/40\n",
      "1400/1400 [==============================] - 0s 174us/step - loss: 5.4780 - acc: 0.6586 - val_loss: 6.1451 - val_acc: 0.6133\n",
      "Epoch 24/40\n",
      "1400/1400 [==============================] - 0s 213us/step - loss: 5.4473 - acc: 0.6600 - val_loss: 6.6411 - val_acc: 0.5833\n",
      "Epoch 25/40\n",
      "1400/1400 [==============================] - 0s 167us/step - loss: 5.4611 - acc: 0.6593 - val_loss: 6.3514 - val_acc: 0.5983\n",
      "Epoch 26/40\n",
      "1400/1400 [==============================] - 0s 167us/step - loss: 5.4340 - acc: 0.6593 - val_loss: 6.4355 - val_acc: 0.5917\n",
      "Epoch 27/40\n",
      "1400/1400 [==============================] - 0s 167us/step - loss: 5.4166 - acc: 0.6614 - val_loss: 6.0417 - val_acc: 0.6233\n",
      "Epoch 28/40\n",
      "1400/1400 [==============================] - 0s 207us/step - loss: 5.4539 - acc: 0.6586 - val_loss: 6.1188 - val_acc: 0.6150\n",
      "Epoch 29/40\n",
      "1400/1400 [==============================] - 0s 163us/step - loss: 5.4139 - acc: 0.6614 - val_loss: 6.0932 - val_acc: 0.6183\n",
      "Epoch 30/40\n",
      "1400/1400 [==============================] - 0s 162us/step - loss: 5.3111 - acc: 0.6686 - val_loss: 6.1668 - val_acc: 0.6150\n",
      "Epoch 31/40\n",
      "1400/1400 [==============================] - 0s 210us/step - loss: 5.3281 - acc: 0.6664 - val_loss: 6.2156 - val_acc: 0.6100\n",
      "Epoch 32/40\n",
      "1400/1400 [==============================] - 0s 217us/step - loss: 5.4438 - acc: 0.6593 - val_loss: 6.2458 - val_acc: 0.6100\n",
      "Epoch 33/40\n",
      "1400/1400 [==============================] - 0s 177us/step - loss: 5.4319 - acc: 0.6607 - val_loss: 6.0075 - val_acc: 0.6233\n",
      "Epoch 34/40\n",
      "1400/1400 [==============================] - 0s 165us/step - loss: 5.2307 - acc: 0.6736 - val_loss: 5.8512 - val_acc: 0.6317\n",
      "Epoch 35/40\n",
      "1400/1400 [==============================] - 0s 167us/step - loss: 5.3948 - acc: 0.6643 - val_loss: 6.1878 - val_acc: 0.6117\n",
      "Epoch 36/40\n",
      "1400/1400 [==============================] - 0s 187us/step - loss: 5.3820 - acc: 0.6650 - val_loss: 5.9346 - val_acc: 0.6283\n",
      "Epoch 37/40\n",
      "1400/1400 [==============================] - 0s 167us/step - loss: 5.3087 - acc: 0.6679 - val_loss: 6.1027 - val_acc: 0.6150\n",
      "Epoch 38/40\n",
      "1400/1400 [==============================] - 0s 203us/step - loss: 5.3532 - acc: 0.6664 - val_loss: 6.0135 - val_acc: 0.6217\n",
      "Epoch 39/40\n",
      "1400/1400 [==============================] - 0s 224us/step - loss: 5.2765 - acc: 0.6707 - val_loss: 5.9325 - val_acc: 0.6250\n",
      "Epoch 40/40\n",
      "1400/1400 [==============================] - 0s 168us/step - loss: 5.2117 - acc: 0.6757 - val_loss: 6.1133 - val_acc: 0.6150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x541aaefc88>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y=to_categorical(y)\n",
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50,activation='relu',input_shape=(784,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50,activation='relu',input_shape=(784,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X,y,validation_split=0.3, epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_155 (Dense)            (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 42,310\n",
      "Trainable params: 42,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
